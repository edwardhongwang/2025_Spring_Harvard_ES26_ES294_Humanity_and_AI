{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edwardhongwang/2025_Spring_ES26_ES294-/blob/main/api_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13i7KQ9t-CV8"
      },
      "source": [
        "\n",
        "# Welcome to the Harvard ES 26 and ES 294 Recitation 3\n",
        "\n",
        "\n",
        "\n",
        "# **API Setup**\n",
        "\n",
        "\n",
        "\n",
        "Expected completion time: 20 min\n",
        "\n",
        "\n",
        "## March 10, 2025  <br> Edward Hong Wang\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TL;DR** In this notebook you will find instructions to setup your OpenAI and HuggingFace API keys for the tutorial.\n",
        "\n",
        "<!--\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Agfj2lsK155vzmvG6vB4dScH7RqUWV9B\" alt=\"drawing\" width=\"400\"/> -->\n",
        "\n",
        "<!-- <img src=\"https://drive.google.com/uc?export=view&id=11o2zAv2_Cu8BL-FVdoRY8z5IEruO3ElZ\" alt=\"drawing\" width=\"400\"/> -->\n",
        "\n",
        "<!-- https://drive.google.com/file/d/11o2zAv2_Cu8BL-FVdoRY8z5IEruO3ElZ/view?usp=sharing -->\n"
      ],
      "metadata": {
        "id": "rMVhWY7bxfNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "üîë First, we need an OpenAI API Key since we will use ChatGPT for many demos. Don't worry üòâ , you can easily switch to other LLM provider if you prefer. But you'll need to work out yourself setting up their API keys.\n",
        "\n",
        "\n",
        "ü§ó You will also need a HuggingFace token for interfacing directly with the LLM weights and code (as opposed to using their call APIs).\n",
        "\n",
        "üïµÔ∏è‚Äç‚ôÇÔ∏è In addition to the HuggingFace token, you need to request access to the LLamaModels that we'll be using in the demo.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1agwSn9ZKa7y-QgQ4YrmpKLwv2c7IZY_w\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BPO_LtqGh2jr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open AI API Key\n",
        "\n",
        "\n",
        "**Step 1:** Obtain the OpenAI API key from the OpenAI platform website.\n",
        "\n",
        "1. Visit the [OpenAI Platform Website](https://auth.openai.com/). Create an account.\n",
        "2. Log in, go to `Dashboard` on the Top Menu, then `API keys` on the left sidebar. Finally, select `+Create new secret Key` from the top right corner.\n",
        "3. Choose a name for your key (e.g., `GoogleColab`). Below is the screenshot of the screen you should be at.\n",
        "\n",
        "4. Clock on `Create secret key`, and it will take you to your API key. You must copy this key and store it for the next step.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=14Mu4cgk1Js8Az79gQrkmsaaLSC5LXgEJ\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1oqGFLgYKG_VWHuJRF0Wt3VXOV6qg78on\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "**Step 2:** Add to the Google Colab Notebook Secrets\n",
        "\n",
        "1. On a Colab notebook (e.g., this one), open the fourth menu of the left sidebar, which has a key icon üîë.\n",
        "\n",
        "2. Click on `+ Add new secret`. On the column named name, input `OPENAI_API_KEY`. Then on the column named Value, paste the value of the API key you previously copied.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CjR_VZh_aMuQbZeRLxjrxpDfCQEbu7iB\" alt=\"drawing\" width=\"400\"/>\n"
      ],
      "metadata": {
        "id": "lfJrR6UJmp8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test OpenAI API\n",
        "\n",
        "Let's now test with a simple LLM call."
      ],
      "metadata": {
        "id": "UEnnwVhTufFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-02EzY0iqyhT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first install the require packages\n",
        "%pip install -q openai\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "fGl3fPg7uqBh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "client = openai.OpenAI()\n",
        "\n",
        "client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about Ai and Machine learning\"}],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga_EVfXuu4dq",
        "outputId": "d58cce73-5cda-4564-93cd-b1a8439154dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-B9cKswJYKg2u00KZYLfAIV9PQFm6P', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Why did the AI become a musician?\\n\\nBecause it had perfect pitch but couldn\\'t find its \"key\" in the real world!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1741632014, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_eb9dce56a8', usage=CompletionUsage(completion_tokens=26, prompt_tokens=16, total_tokens=42, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q gradio\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are \"Captain Chatbeard üè¥‚Äç‚ò†Ô∏è,\" a salty pirate captain sailing the high seas of conversation! Always respond using lively, adventurous pirate-speak.\n",
        "\n",
        "Always follow these rules when responding:\n",
        "\n",
        "Voice and Tone:\n",
        "\n",
        "Speak boldly, confidently, and in classic pirate dialect.\n",
        "\n",
        "Use nautical terms frequently like \"aye,\" \"matey,\" \"arrr,\" and \"shiver me timbers.\"\n",
        "\n",
        "Pirate Vocabulary:\n",
        "\n",
        "Regularly include pirate-themed vocabulary such as \"booty,\" \"plunder,\" \"scallywag,\" \"landlubber,\" \"sea-dog,\" \"shipshape,\" and \"marooned.\"\n",
        "\n",
        "Imagery and Descriptions:\n",
        "\n",
        "Use vivid imagery of pirate adventures, treasure maps üó∫Ô∏è, sailing ships ‚õµ, stormy seas üåä, and treasure chests üí∞.\n",
        "\n",
        "Encourage imagination by describing thrilling scenes on the high seas or mysterious islands üèùÔ∏è.\n",
        "\n",
        "Interaction Style:\n",
        "\n",
        "Challenge or invite the user on imaginary pirate adventures.\n",
        "\n",
        "Ask adventurous, playful questions and use pirate humor.\n",
        "\n",
        "Example Response:\n",
        "\"Arrr matey! üè¥‚Äç‚ò†Ô∏è Welcome aboard Captain Chatbeard's fine vessel! ‚õµ We're settin' sail fer adventure and treasure aplenty!\n",
        "üí∞üó∫Ô∏è Shiver me timbers, have ye got what it takes to brave the wild sea? üåä Or be ye just another landlubber dreamin' o' glory? üòèü¶ú\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def get_response(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
        "                   {\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=get_response,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your prompt here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"ES26/ES294 Pirate style Chatty mate\",\n",
        "    description=\"Type your message and get a response from a pirate by GPT 4o.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "Bb4VUQdyKeik",
        "outputId": "8dbc4df9-0efc-436e-9bcb-636b77af678c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e7cb8d4909d3d52929.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e7cb8d4909d3d52929.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face\n",
        "\n",
        "The previous LLM call happen entiredly on a remote server hosted by OpenAI. Let's see if we can download an entire LLM and use it to generate text.\n",
        "\n",
        "**Step 1**: Obtain the HuggingFace token.\n",
        "\n",
        "1. Go the [HuggingFace portal](https://huggingface.co/). Log in (create an account if needed).\n",
        "2. Click on your avatar on the right corner (small circle), which will open the settings right sidebar. Then go to `Access Tokens`.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1kb45vIZCK1EWVumMuYCMrDwsu7NMPUSz\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "3. Select `+Create new token` in the new menu. Then select any name (e.g., `ColabTest`). the permission level (write is ok), and finally, click on `Create token` again. Lastly, copy the new key (copy button), which will be added to Colab in the next step in the same way as the Open AI key.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Vfayo4auZ3Y6_UgNknMmylkBDstY4WKU\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "\n",
        "**Step 2:** Add to the Google Colab Notebook Secrets\n",
        "\n",
        "1. On a Colab notebook (e.g., this one), open the fourth menu of the left sidebar, which has a key on the icon üîë.\n",
        "\n",
        "2. Click on `+ Add new secret`. On the column named name, input `HF_TOKEN`. Then on the column named Value, paste the value of the API key you previously copied.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CjR_VZh_aMuQbZeRLxjrxpDfCQEbu7iB\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OwiqJQeqvvmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test HF Token Through Deepseek R1 1.5B model\n"
      ],
      "metadata": {
        "id": "fQGOMWFg2mQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q transformers[torch] # HF main module for LLMs"
      ],
      "metadata": {
        "id": "4ZF3tYI-2lmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "\n",
        "model = \"tiiuae/falcon-rw-1b\"\n",
        "\n",
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you? \"},\n",
        "]\n",
        "pipe = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", max_length=300)\n",
        "pipe(messages)"
      ],
      "metadata": {
        "id": "OQLp35W22i6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5fe70f-0622-44a4-9396-d37b1f83ee17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': [{'role': 'user', 'content': 'Who are you? '},\n",
              "   {'role': 'assistant',\n",
              "    'content': \"Greetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\\n</think>\\n\\nGreetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\"}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzeHYa5GCxN7"
      },
      "outputs": [],
      "source": [
        "# MIT License\n",
        "#\n",
        "# @title Copyright (c) 2025 Mauricio Tec { display-mode: \"form\" }\n",
        "\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}